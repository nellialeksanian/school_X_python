{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92af260f-d134-42e7-bd05-715f579f4b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99513ab4-ba4d-4f83-8787-b976a90ef3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f81b7b2c-b2b2-4911-b59a-834b933af0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -Uq accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4336eb-2885-4dc2-b002-6829df2565b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596420d9-e3d7-44c3-8072-142d2d913566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495e77e-fbce-4556-ab2a-e42aa5c13abe",
   "metadata": {},
   "source": [
    "Для решения задачи я выбрала трансформер distillbert, так как в отличии от gpt, задачей которого является генерация текста, bert лучше справляется с задачей классификации и анализа текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c40f3c-258a-47c2-8805-c63c9ec28c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "transformer_model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147924d0-d0de-4ec6-a32b-56ed79b49c78",
   "metadata": {},
   "source": [
    "Так я датасет я уже аугментировала для решения задачи с помощью других моделей, я их сохранила в формате csv и импортировала здесь "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10c9e3b3-b358-46c8-871e-0644602c1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('train_augmented.csv')\n",
    "X_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f56c31e4-12c0-4e27-9b7f-40369136045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('sms', axis=1)\n",
    "X_test = X_test.drop('sms', axis=1)\n",
    "X_test['label'] = X_test['label'].astype(int)\n",
    "X_train['label'] = X_train['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eb8e9da-372d-451c-9895-b8acd907b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de100a08-e832-474f-885b-f5628c478122",
   "metadata": {},
   "source": [
    "\n",
    "Для того чтобы сделать обучением более сбалансированным (учитывая что датасет несбалансирован) я расcчитала веса для каждого класса, чтобы использовать это в процессе обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8193395c-524f-49a7-ac5b-0361b719bc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2417, 0.7583])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = torch.tensor(1 - (X_train[\"label\"].value_counts().sort_index() / len(X_train))).float() \n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c2f8d4a-f396-478f-88c7-746c617d2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Dataset.from_pandas(X_train)\n",
    "X_test = Dataset.from_pandas(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a867ab98-5e9d-4fd9-aee1-d61f65bda84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439c91c680ef4605a419fc62cc1f8eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d84d2bd18754e91b3a2ef5b3fbb5083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['clean_text'],  padding='max_length', truncation=True)\n",
    "train_tokens = X_train.map(tokenize_function, batched=True)\n",
    "test_tokens = X_test.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80f1b2ef-c9ed-4483-9624-574aaee049be",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_outputs\",                  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7c43c24-eba0-47f5-b231-e301be35be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26512f8c-03fe-4e7b-b090-8fa247a1bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \n",
    "        outputs = model(**inputs) \n",
    "        logits = outputs.get(\"logits\") \n",
    "        labels = inputs.get (\"labels\") \n",
    "        loss = CrossEntropyLoss(weight = class_weights) \n",
    "        \n",
    "        return (loss(logits, labels), outputs) if return_outputs else loss(logits, labels)\n",
    "\n",
    "custom_trainer = CustomTrainer(\n",
    "    model=transformer_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokens,\n",
    "   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "269c29a9-9fbb-4515-9917-7f628230649b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1899' max='1899' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1899/1899 3:37:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.139900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.041300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1899, training_loss=0.049288335585355635, metrics={'train_runtime': 13052.1347, 'train_samples_per_second': 1.164, 'train_steps_per_second': 0.145, 'total_flos': 2012444720381952.0, 'train_loss': 0.049288335585355635, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f3f1ae0-427a-4a63-b1e1-39dec1342bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = custom_trainer.predict(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c8891d-6074-4304-b1f0-c994eefd176d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9919282511210762}\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = compute_metrics((predictions.predictions,test_tokens['label']))\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c35579b-8904-4f4d-acbe-07f2c0587ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       0.98      0.95      0.97       135\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.99      0.97      0.98      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report_trans = classification_report(test_tokens['label'], np.argmax(predictions.predictions, axis=-1))\n",
    "print(classification_report_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d32aaae2-90f4-41a3-9cce-a6b48ef7e1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./new_tokenizer/tokenizer_config.json',\n",
       " './new_tokenizer/special_tokens_map.json',\n",
       " './new_tokenizer/vocab.txt',\n",
       " './new_tokenizer/added_tokens.json',\n",
       " './new_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./new_model\")\n",
    "tokenizer.save_pretrained('./new_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3c5f728-896f-4570-95bd-9733ef8315d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = AutoModelForSequenceClassification.from_pretrained(\"./new_model\")\n",
    "my_tokenizer = AutoTokenizer.from_pretrained('./new_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86bbebe9-5dee-4807-8371-b37b3fcb9fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9995879530906677}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "pipe = TextClassificationPipeline(model=my_model, tokenizer=my_tokenizer)\n",
    "input_text = 'Congratulations! You’ve won a $500 Amazon gift card. Claim it here [Link]. '\n",
    "pipe(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655691f8-ed2d-41c6-82ac-7b0d658419ff",
   "metadata": {},
   "source": [
    "Вывод: лучше всех результаты показал трансформер<br>\n",
    "Несмотря на это стоит отметить что на обучение трансформера ушло очень много времени, хотя другие модели выполняют задачу не сильно хуже"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
